{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnoiprem/honest-colab/blob/main/kafka_stream_data_lake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W61KPiPm-y0m"
      },
      "outputs": [],
      "source": [
        "# ETL using realtime (Kafka + spark )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Engineering Assessment Test:\n",
        "\n",
        "IMPORTANT:\n",
        "- Build the system on a cloud environment.\n",
        "\n",
        "\n",
        "INSTRUCTIONS:\n",
        "\n",
        "Download the data from https://www.kaggle.com/wordsforthewise/lending-club. Use the file called rejected_2007_to_2018Q4.csv for the following assignment:\n",
        "1. Using just the data in 2007, we are interested in the Moving Average of the Risk_Score column (50 rows back). Calculate the MA(50) of the Risk_Score and put it in a new column called RiskScoreMA50. Store this in a Data Store of your choice.\n",
        "2. Starting in year 2008 to 2009, mock up a Kafka Stream of the data coming into the system. Calculate the MA50 for the incoming Risk Score as well. Then store the data in the data store.\n",
        "3. Starting year 2009 onwards, you get a new requirement to also calculate the MA100 of the Risk Score and store it, but the data schema must also to be trackable. Make a new column on the data store that has a new column called MA100, update the version of this data store, and do version controlling so that the original features can easily be accessed.\n",
        "4. The team found out that they did not actually want the MA50, but the EMA50 for the purpose of this calculation (want to edit the feature without changing the name). In this case, they do not want a new column for the EMA50, but replace the existing MA50 with new logic. Edit the logic for the feature creation pipeline, and version control the new version of the feature store.\n",
        "\n",
        "\n",
        "Bonus Points:\n",
        "\n",
        "1. Submission of a video demo of the system you built.\n",
        "\n",
        "\n",
        "![image](diagram.png)\n",
        "# New Section"
      ],
      "metadata": {
        "id": "ZtjvS02MQ4IR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDrVSIrF_RfC"
      },
      "source": [
        "*italicized text*#1.Setup standalone Spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QCvXCcq_NXb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Aeq9Zm_feH"
      },
      "source": [
        "https://databricks.com/discover/demos/delta-**lake**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jbIntfW_aJn",
        "outputId": "174b051a-375b-45bb-f436-644a79516e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (108.157.162.119)] [\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connected to cloud.r-projec\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connected to cloud.r-projec\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connected to cloud.r-projec\r                                                                               \rHit:5 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Qm13rjJ5_kfK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import abspath\n",
        "\n",
        "import site\n",
        "import time\n",
        "import requests\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecH_FsAM_pqe",
        "outputId": "e5434416-ded4-4647-cf0b-db60b71e1048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 12 20:45:22 +08 2022\n"
          ]
        }
      ],
      "source": [
        "# update the time to local time\n",
        "!rm /etc/localtime\n",
        "!ln -s /usr/share/zoneinfo/Asia/Singapore /etc/localtime\n",
        "!date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9o3jxx-_tNm",
        "outputId": "67dd8174-fa34-4dec-a9df-8587205f77b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark==3.0.3 in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark==3.0.3) (0.10.9)\n",
            "openjdk-8-jdk-headless is already the newest version (8u312-b07-0ubuntu1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 87 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "'''define sparkhome just in case there would be a situation where I need it later on\n",
        "This method doesnt come with Hadoop binaries which could impair some functions'''\n",
        "def get_pyspark():\n",
        "  !pip install pyspark==3.0.3\n",
        "  PACKAGES_PATH = site.getsitepackages()[0]\n",
        "  os.environ[\"SPARK_HOME\"] = f\"{PACKAGES_PATH}/pyspark\"\n",
        "get_pyspark()\n",
        "'''PyDrive is a high-level Python wrapper for the Google Drive API. \n",
        "It allows you to easily upload, download, and delete files in your Google Drive from a Python script'''\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "#downlad java because some task will requires the Java Virtual Machine (JVM) to run. \n",
        "\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzuCJAdrAoSO",
        "outputId": "c1ca7889-7311-4345-ea85-32d807657011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2043692\n",
            "-rw-r--r-- 1 root root  392582231 Dec 17  2019  accepted_2007_to_2018Q4.csv.gz\n",
            "-rw-r--r-- 1 root root  255470782 Dec 17  2019  rejected_2007_to_2018Q4.csv.gz\n",
            "drwxr-xr-x 8 root root       4096 Jan 12 17:07  kafka_2.13-3.1.0\n",
            "drwxr-xr-x 1 root root       4096 Jun  1 21:50  sample_data\n",
            "-rw-r--r-- 1 root root         67 Jun 12 16:25  kaggle.json\n",
            "-rw-r--r-- 1 root root 1356507910 Jun 12 16:26  lending-club.zip\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 16:26  accepted_2007_to_2018q4.csv\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 16:26  rejected_2007_to_2018q4.csv\n",
            "drwxr-xr-x 3 root root       4096 Jun 12 18:00  sample_rejected_2007_to_2018Q4\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 18:41  spark-warehouse\n",
            "-rw-r--r-- 1 root root         67 Jun 12 19:45 'kaggle (1).json'\n",
            "-rw-r--r-- 1 root root   88130011 Jun 12 19:49  kafka_2.13-3.1.0.tgz\n"
          ]
        }
      ],
      "source": [
        "!ls -lrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "_R4cefozA2Ak"
      },
      "outputs": [],
      "source": [
        "#1)Download the data from https://www.kaggle.com/wordsforthewise/lending-club. Use the file called rejected_2007_to_2018Q4.csv for the following assignment:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQvA9CP0BA0c"
      },
      "source": [
        "Kaggle data\n",
        "# Easiest way to download kaggle data in Google Colab Posted in General 3 years ago 698\n",
        "\n",
        "# Please follow the steps below to download and use kaggle data within Google Colab:\n",
        "\n",
        "# Go to your account, Scroll to API section and Click Expire API Token to remove previous tokens\n",
        "\n",
        "# Click on Create New API Token - It will download kaggle.json file on your machine.\n",
        "\n",
        "# Go to your Google Colab project file and run the following commands:\n",
        "\n",
        "# 1) ! pip install -q kaggle\n",
        "\n",
        "# 2) from google.colab import files\n",
        "\n",
        "# files.upload()\n",
        "\n",
        "# Choose the kaggle.json file that you downloaded 3) ! mkdir ~/.kaggle\n",
        "\n",
        "# ! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Make directory named kaggle and copy kaggle.json file there. 4) ! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Change the permissions of the file. 5) ! kaggle datasets list\n",
        "\n",
        "# That's all ! You can check if everything's okay by running this command.\n",
        "# Download Data ! kaggle competitions download -c 'name-of-competition'\n",
        "\n",
        "# Use unzip command to unzip the data:\n",
        "\n",
        "# For example,\n",
        "\n",
        "# Create a directory named train,\n",
        "\n",
        "# ! mkdir train\n",
        "\n",
        "# unzip train data there,\n",
        "\n",
        "# ! unzip train.zip -d train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "VH6WW9-yBD9k",
        "outputId": "8335268f-3d13-4d13-b193-10cbc5ce3b7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2ce302ce-75f3-42db-a19b-2609bf7d3486\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2ce302ce-75f3-42db-a19b-2609bf7d3486\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "_4KWDZp8BG4b",
        "outputId": "26af5e4e-b644-409f-b2f2-ecbc064e1ce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "lending-club.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  lending-club.zip\n",
            "replace accepted_2007_to_2018Q4.csv.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: accepted_2007_to_2018Q4.csv.gz  n\n",
            "\n",
            "replace accepted_2007_to_2018q4.csv/accepted_2007_to_2018Q4.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: replace rejected_2007_to_2018Q4.csv.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace rejected_2007_to_2018q4.csv/rejected_2007_to_2018Q4.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9d50c12f1d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kaggle datasets download -d wordsforthewise/lending-club'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip lending-club.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d wordsforthewise/lending-club\n",
        "!unzip lending-club.zip\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bNScX_1UBUp7"
      },
      "outputs": [],
      "source": [
        "!curl -sSOL https://dlcdn.apache.org/kafka/3.1.0/kafka_2.13-3.1.0.tgz\n",
        "!tar -xzf kafka_2.13-3.1.0.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrNTC_IFCHpB",
        "outputId": "8ea99305-f6b3-4b31-e660-c96edf30b6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 10 secs until kafka and zookeeper services are up and running\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.13-3.1.0/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-3.1.0/config/zookeeper.properties\n",
        "!./kafka_2.13-3.1.0/bin/kafka-server-start.sh -daemon ./kafka_2.13-3.1.0/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5N1BLECCK7w",
        "outputId": "29328df1-227f-43ac-baf3-ef8a338c4c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.\n",
            "Error while executing topic command : Topic 'rejected_2007_to_2018' already exists.\n",
            "[2022-06-12 12:48:24,791] ERROR org.apache.kafka.common.errors.TopicExistsException: Topic 'rejected_2007_to_2018' already exists.\n",
            " (kafka.admin.TopicCommand$)\n",
            "Topic: rejected2007to2018\tTopicId: fdQyOCm6S6uXpv5egAk8kg\tPartitionCount: 1\tReplicationFactor: 1\tConfigs: segment.bytes=1073741824\n",
            "\tTopic: rejected2007to2018\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic rejected_2007_to_2018\n",
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic rejected2007to2018\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUOel48XCaj9",
        "outputId": "9b300373-7658-4e10-f04d-99212fa94b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kafka-python in /usr/local/lib/python3.7/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kafka-python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R2KJxRTClju"
      },
      "source": [
        "#kafka producer to produce data in the topic: rejected_2007_to_2018\n",
        "\n",
        "2. Starting in year 2008 to 2009, mock up a Kafka Stream of the data coming into the system. Calculate the MA50 for the incoming Risk Score as well. Then store the data in the data store.\n",
        "rejected_2007_to_2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nsgdPBvLCjPm"
      },
      "outputs": [],
      "source": [
        "from kafka import KafkaAdminClient, KafkaConsumer, KafkaProducer\n",
        "from kafka.admin import NewTopic\n",
        "import json\n",
        "from json import loads\n",
        "import threading\n",
        "\n",
        "from csv import DictReader\n",
        "\n",
        "def kafka_producer_csv():\n",
        "  # Required setting for Kafka Producer\n",
        "  bootstrap_servers = ['localhost:9092']\n",
        "  topicname = 'rejected_2007_to_2018'\n",
        "  producer = KafkaProducer(bootstrap_servers = bootstrap_servers)\n",
        "  producer = KafkaProducer()\n",
        "  # iterate over each line as a ordered dictionary and print only few column by column name\n",
        "  with open('rejected_2007_to_2018q4.csv/rejected_2007_to_2018Q4.csv','r') as read_obj:\n",
        "      csv_dict_reader = DictReader(read_obj)\n",
        "      for row in csv_dict_reader:\n",
        "          ack = producer.send(topicname, json.dumps(row).encode('utf-8'))\n",
        "          metadata = ack.get()\n",
        "          # print(metadata.topic, metadata.partition)\n",
        "\n",
        "threading.Thread(target=kafka_producer_csv).start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZpOhEIwCprT",
        "outputId": "bdb2463a-00fd-4e33-8e69-393bf8fcae96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: rejected_2007_to_2018\tTopicId: wwzKe7NLQK-hM325UPldQA\tPartitionCount: 1\tReplicationFactor: 1\tConfigs: segment.bytes=1073741824\n",
            "\tTopic: rejected_2007_to_2018\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic rejected_2007_to_2018\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1DrZ3n7CyQn",
        "outputId": "d6c056c4-ee4e-4a44-8dde-9e097601594a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"Amount Requested\": \"1000.0\", \"Application Date\": \"2007-05-26\", \"Loan Title\": \"Wedding Covered but No Honeymoon\", \"Risk_Score\": \"693.0\", \"Debt-To-Income Ratio\": \"10%\", \"Zip Code\": \"481xx\", \"State\": \"NM\", \"Employment Length\": \"4 years\", \"Policy Code\": \"0.0\"}\n",
            "{\"Amount Requested\": \"1000.0\", \"Application Date\": \"2007-05-26\", \"Loan Title\": \"Consolidating Debt\", \"Risk_Score\": \"703.0\", \"Debt-To-Income Ratio\": \"10%\", \"Zip Code\": \"010xx\", \"State\": \"MA\", \"Employment Length\": \"< 1 year\", \"Policy Code\": \"0.0\"}\n",
            "{\"Amount Requested\": \"11000.0\", \"Application Date\": \"2007-05-27\", \"Loan Title\": \"Want to consolidate my debt\", \"Risk_Score\": \"715.0\", \"Debt-To-Income Ratio\": \"10%\", \"Zip Code\": \"212xx\", \"State\": \"MD\", \"Employment Length\": \"1 year\", \"Policy Code\": \"0.0\"}\n",
            "{\"Amount Requested\": \"6000.0\", \"Application Date\": \"2007-05-27\", \"Loan Title\": \"waksman\", \"Risk_Score\": \"698.0\", \"Debt-To-Income Ratio\": \"38.64%\", \"Zip Code\": \"017xx\", \"State\": \"MA\", \"Employment Length\": \"< 1 year\", \"Policy Code\": \"0.0\"}\n",
            "{\"Amount Requested\": \"1500.0\", \"Application Date\": \"2007-05-27\", \"Loan Title\": \"mdrigo\", \"Risk_Score\": \"509.0\", \"Debt-To-Income Ratio\": \"9.43%\", \"Zip Code\": \"209xx\", \"State\": \"MD\", \"Employment Length\": \"< 1 year\", \"Policy Code\": \"0.0\"}\n",
            "Processed a total of 5 messages\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.13-3.1.0/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic rejected_2007_to_2018 --from-beginning --max-messages 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XOAm3XjfDKGx"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_UjVTFnScv1",
        "outputId": "0fdff1b0-bde4-40d2-88c8-ee8d8c7946f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "d-d5bhvCSME4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pfy3W-dEScGs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dfMRBODGGuFI"
      },
      "outputs": [],
      "source": [
        "# spark = pyspark.sql.SparkSession.builder.appName(\"Group7\") \\\n",
        "#   .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.3,org.apache.kafka:kafka-clients:2.13-3.1.0\") \\\n",
        "#   .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "#   .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "#   .config('spark.ui.port', '4050')\\\n",
        "#   .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QDkujIalC4_H"
      },
      "outputs": [],
      "source": [
        "spark = pyspark.sql.SparkSession.builder.appName(\"Group7\") \\\n",
        "  .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.7.0\") \\\n",
        "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
        "    .config('spark.ui.port', '4050')\\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TSCVLkN1GtRl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:3.0.3 pyspark-shell'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-3qe-5XFJnW"
      },
      "outputs": [],
      "source": [
        "# spark_version='3.0.3'\n",
        "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:{}'.format(spark_version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Q_UPq7XLDhJ8",
        "outputId": "1e93d041-a565-499a-8b2a-4a48e75cf2c6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d74084dfe1a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkafka_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadStream\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kafka\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kafka.bootstrap.servers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"localhost:9092\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kafka.security.protocol\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SSL\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failOnDataLoss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"false\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"subscribe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rejected_2007_to_2018\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"includeHeaders\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"startingOffsets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"latest\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.streaming.kafka.maxRatePerPartition\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Failed to find data source: kafka. Please deploy the application as per the deployment section of \"Structured Streaming + Kafka Integration Guide\".;"
          ]
        }
      ],
      "source": [
        "kafka_df = spark.readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "    .option(\"kafka.security.protocol\", \"SSL\") \\\n",
        "    .option(\"failOnDataLoss\", \"false\") \\\n",
        "    .option(\"subscribe\", \"rejected_2007_to_2018\") \\\n",
        "    .option(\"includeHeaders\", \"true\") \\\n",
        "    .option(\"startingOffsets\", \"latest\") \\\n",
        "    .option(\"spark.streaming.kafka.maxRatePerPartition\", \"2\") \\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "KAolbMrQDo8c",
        "outputId": "3504edd8-8443-4e5f-d2f4-ac29c07b75ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6a27a82610>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://bfb5cd37d43d:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Group7</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjGTpwKaDx0Z"
      },
      "outputs": [],
      "source": [
        "# spark is not working so i am try to FLINK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BRWSKKXTQPD",
        "outputId": "636f51b8-bdfe-40d9-91d2-52f6beb3832c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: apache-flink in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (2.28.0)\n",
            "Requirement already satisfied: pandas<1.2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (1.1.5)\n",
            "Requirement already satisfied: protobuf<3.18 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (3.17.3)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (2022.1)\n",
            "Requirement already satisfied: numpy<1.20,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (1.19.5)\n",
            "Requirement already satisfied: fastavro<0.24,>=0.21.4 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (0.23.6)\n",
            "Requirement already satisfied: pemja==0.1.4 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (0.1.4)\n",
            "Requirement already satisfied: avro-python3!=1.9.2,<1.10.0,>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (1.9.2.1)\n",
            "Requirement already satisfied: apache-flink-libraries<1.15.1,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil==2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (2.8.0)\n",
            "Requirement already satisfied: pyarrow<3.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (2.0.0)\n",
            "Collecting py4j==0.10.9.3\n",
            "  Using cached py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "Requirement already satisfied: apache-beam==2.27.0 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (2.27.0)\n",
            "Requirement already satisfied: cloudpickle==1.2.2 in /usr/local/lib/python3.7/dist-packages (from apache-flink) (1.2.2)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (3.12.3)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (1.46.3)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (2.7.0)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (4.1.3)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (0.3.1.1)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (1.3.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (1.7)\n",
            "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (2.0.0)\n",
            "Requirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (0.17.4)\n",
            "Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam==2.27.0->apache-flink) (0.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil==2.8.0->apache-flink) (1.15.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam==2.27.0->apache-flink) (0.6.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.7/dist-packages (from mock<3.0.0,>=1.0.1->apache-beam==2.27.0->apache-flink) (5.9.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam==2.27.0->apache-flink) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam==2.27.0->apache-flink) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam==2.27.0->apache-flink) (0.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot<2,>=1.2.0->apache-beam==2.27.0->apache-flink) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->apache-flink) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->apache-flink) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->apache-flink) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26.0->apache-flink) (2.10)\n",
            "Installing collected packages: py4j\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9\n",
            "    Uninstalling py4j-0.10.9:\n",
            "      Successfully uninstalled py4j-0.10.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyspark 3.0.3 requires py4j==0.10.9, but you have py4j 0.10.9.3 which is incompatible.\n",
            "delta-spark 1.2.1 requires pyspark<3.3.0,>=3.2.0, but you have pyspark 3.0.3 which is incompatible.\u001b[0m\n",
            "Successfully installed py4j-0.10.9.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "##Speark streaming now working so trying FLINK\n",
        "\n",
        "!python -m pip install apache-flink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ODD1o-t8TWh8"
      },
      "outputs": [],
      "source": [
        "kafka_df = spark.read.csv(\"rejected_2007_to_2018q4.csv/rejected_2007_to_2018Q4.csv\",header=True).withColumn(\"user_Read_time\",current_timestamp()) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nXUnnSlpUMpg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvvkdIpAUZ5S"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "[link text](https://)# 4.Demo Spark and Delta Lake```\n",
        "\n",
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1EOkyBdUbKC",
        "outputId": "c83907ce-1383-4da1-88ac-bba5278844ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "|Amount Requested|Application Date|          Loan Title|Risk_Score|Debt-To-Income Ratio|Zip Code|State|Employment Length|Policy Code|      user_Read_time|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "|          1000.0|      2007-05-26|Wedding Covered b...|     693.0|                 10%|   481xx|   NM|          4 years|        0.0|2022-06-12 12:54:...|\n",
            "|          1000.0|      2007-05-26|  Consolidating Debt|     703.0|                 10%|   010xx|   MA|         < 1 year|        0.0|2022-06-12 12:54:...|\n",
            "|         11000.0|      2007-05-27|Want to consolida...|     715.0|                 10%|   212xx|   MD|           1 year|        0.0|2022-06-12 12:54:...|\n",
            "|          6000.0|      2007-05-27|             waksman|     698.0|              38.64%|   017xx|   MA|         < 1 year|        0.0|2022-06-12 12:54:...|\n",
            "|          1500.0|      2007-05-27|              mdrigo|     509.0|               9.43%|   209xx|   MD|         < 1 year|        0.0|2022-06-12 12:54:...|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "kafka_df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x8ZXQiXUeRt",
        "outputId": "a76ef6b9-fef5-49be-c9fe-7bb445dd84d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Amount Requested',\n",
              " 'Application Date',\n",
              " 'Loan Title',\n",
              " 'Risk_Score',\n",
              " 'Debt-To-Income Ratio',\n",
              " 'Zip Code',\n",
              " 'State',\n",
              " 'Employment Length',\n",
              " 'Policy Code',\n",
              " 'user_Read_time']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "kafka_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svFO5qCgUvnG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-ib4wvmVVfA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyG0u78DVjDo",
        "outputId": "ecf5d966-b9e2-43e1-9a70-a76ee25a2438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Amount Requested', 'Application Date', 'Loan Title', 'Risk_Score', 'Debt-To-Income Ratio', 'Zip Code', 'State', 'Employment Length', 'Policy Code', 'user_Read_time']\n",
            "['amount_requested', 'application_date', 'loan_title', 'risk_score', 'debt_to_income_ratio', 'zip_code', 'state', 'employment_length', 'policy_code', 'user_read_time']\n"
          ]
        }
      ],
      "source": [
        "from functools import reduce\n",
        "\n",
        "oldColumns = kafka_df.schema.names\n",
        "print(oldColumns)\n",
        "new_columns=['amount_requested','application_date','loan_title','risk_score','debt_to_income_ratio','zip_code','state','employment_length','policy_code','user_read_time']\n",
        "print(new_columns)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfN1oUA3f4mU",
        "outputId": "3e43da10-e227-495c-e3d6-9768acb574f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- amount_requested: string (nullable = true)\n",
            " |-- application_date: string (nullable = true)\n",
            " |-- loan_title: string (nullable = true)\n",
            " |-- risk_score: string (nullable = true)\n",
            " |-- debt_to_income_ratio: string (nullable = true)\n",
            " |-- zip_code: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- employment_length: string (nullable = true)\n",
            " |-- policy_code: string (nullable = true)\n",
            " |-- user_read_time: timestamp (nullable = false)\n",
            "\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "|amount_requested|application_date|          loan_title|risk_score|debt_to_income_ratio|zip_code|state|employment_length|policy_code|      user_read_time|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "|          1000.0|      2007-05-26|Wedding Covered b...|     693.0|                 10%|   481xx|   NM|          4 years|        0.0|2022-06-12 12:58:...|\n",
            "|          1000.0|      2007-05-26|  Consolidating Debt|     703.0|                 10%|   010xx|   MA|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|         11000.0|      2007-05-27|Want to consolida...|     715.0|                 10%|   212xx|   MD|           1 year|        0.0|2022-06-12 12:58:...|\n",
            "|          6000.0|      2007-05-27|             waksman|     698.0|              38.64%|   017xx|   MA|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|          1500.0|      2007-05-27|              mdrigo|     509.0|               9.43%|   209xx|   MD|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|         15000.0|      2007-05-27|          Trinfiniti|     645.0|                  0%|   105xx|   NY|          3 years|        0.0|2022-06-12 12:58:...|\n",
            "|         10000.0|      2007-05-27|         NOTIFYi Inc|     693.0|                 10%|   210xx|   MD|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|          3900.0|      2007-05-27|         For Justin.|     700.0|                 10%|   469xx|   IN|          2 years|        0.0|2022-06-12 12:58:...|\n",
            "|          3000.0|      2007-05-28|              title?|     694.0|                 10%|   808xx|   CO|          4 years|        0.0|2022-06-12 12:58:...|\n",
            "|          2500.0|      2007-05-28|            timgerst|     573.0|              11.76%|   407xx|   KY|          4 years|        0.0|2022-06-12 12:58:...|\n",
            "|          3900.0|      2007-05-28| need to consolidate|     710.0|                 10%|   705xx|   LA|        10+ years|        0.0|2022-06-12 12:58:...|\n",
            "|          1000.0|      2007-05-28|          sixstrings|     680.0|                 10%|   424xx|   KY|           1 year|        0.0|2022-06-12 12:58:...|\n",
            "|          3000.0|      2007-05-28|          bmoore5110|     688.0|                 10%|   190xx|   PA|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|          1500.0|      2007-05-28|            MHarkins|     704.0|                 10%|   189xx|   PA|          3 years|        0.0|2022-06-12 12:58:...|\n",
            "|          1000.0|      2007-05-28|              Moving|     694.0|                 10%|   354xx|   AL|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|          8000.0|      2007-05-28|Recent College Gr...|     708.0|                 10%|   374xx|   TN|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|         12000.0|      2007-05-29|    FoundersCafe.com|     685.0|                 10%|   770xx|   TX|          3 years|        0.0|2022-06-12 12:58:...|\n",
            "|          1000.0|      2007-05-29|        UChicago2004|     698.0|                 10%|   207xx|   MD|          3 years|        0.0|2022-06-12 12:58:...|\n",
            "|         15000.0|      2007-05-29|Cancer is Killing...|     680.0|                 10%|   432xx|   OH|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "|          5000.0|      2007-05-29|2006-2007 College...|     680.0|                 10%|   011xx|   MA|         < 1 year|        0.0|2022-06-12 12:58:...|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        " df = reduce(lambda data, idx: data.withColumnRenamed(oldColumns[idx], new_columns[idx]), range(len(oldColumns)), kafka_df)\n",
        " df.printSchema()\n",
        " df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHZbfR69_nrY",
        "outputId": "cf358b0d-49f5-4d73-8b1f-3339af358829"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "|amount_requested|application_date|          loan_title|risk_score|debt_to_income_ratio|zip_code|state|employment_length|policy_code|      user_read_time|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "|          1000.0|      2007-05-26|Wedding Covered b...|     693.0|                 10%|   481xx|   NM|          4 years|        0.0|2022-06-12 13:01:...|\n",
            "|          1000.0|      2007-05-26|  Consolidating Debt|     703.0|                 10%|   010xx|   MA|         < 1 year|        0.0|2022-06-12 13:01:...|\n",
            "|         11000.0|      2007-05-27|Want to consolida...|     715.0|                 10%|   212xx|   MD|           1 year|        0.0|2022-06-12 13:01:...|\n",
            "|          6000.0|      2007-05-27|             waksman|     698.0|              38.64%|   017xx|   MA|         < 1 year|        0.0|2022-06-12 13:01:...|\n",
            "|          1500.0|      2007-05-27|              mdrigo|     509.0|               9.43%|   209xx|   MD|         < 1 year|        0.0|2022-06-12 13:01:...|\n",
            "|         15000.0|      2007-05-27|          Trinfiniti|     645.0|                  0%|   105xx|   NY|          3 years|        0.0|2022-06-12 13:01:...|\n",
            "|         10000.0|      2007-05-27|         NOTIFYi Inc|     693.0|                 10%|   210xx|   MD|         < 1 year|        0.0|2022-06-12 13:01:...|\n",
            "|          3900.0|      2007-05-27|         For Justin.|     700.0|                 10%|   469xx|   IN|          2 years|        0.0|2022-06-12 13:01:...|\n",
            "|          3000.0|      2007-05-28|              title?|     694.0|                 10%|   808xx|   CO|          4 years|        0.0|2022-06-12 13:01:...|\n",
            "|          2500.0|      2007-05-28|            timgerst|     573.0|              11.76%|   407xx|   KY|          4 years|        0.0|2022-06-12 13:01:...|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "m9tpzS7HVrHb"
      },
      "outputs": [],
      "source": [
        "df.write.format(\"delta\").mode(\"overwrite\").save(\"output_rejected_2007_to_2018Q4\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JQYWhjt-_mrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgAQdgIKWB1S",
        "outputId": "aa1f2ba4-1cf2-4651-b500-226d35ea24a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 2043696\n",
            "drwxr-xr-x 1 root root       4096 Jun 12 17:56 .\n",
            "drwxr-xr-x 1 root root       4096 Jun 12 16:15 ..\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 16:26 accepted_2007_to_2018q4.csv\n",
            "-rw-r--r-- 1 root root  392582231 Dec 17  2019 accepted_2007_to_2018Q4.csv.gz\n",
            "drwxr-xr-x 4 root root       4096 Jun  1 21:49 .config\n",
            "drwxr-xr-x 8 root root       4096 Jun 12 16:29 kafka_2.13-3.1.0\n",
            "-rw-r--r-- 1 root root   88130011 Jun 12 16:29 kafka_2.13-3.1.0.tgz\n",
            "-rw-r--r-- 1 root root         67 Jun 12 16:25 kaggle.json\n",
            "-rw-r--r-- 1 root root 1356507910 Jun 12 16:26 lending-club.zip\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 16:26 rejected_2007_to_2018q4.csv\n",
            "-rw-r--r-- 1 root root  255470782 Dec 17  2019 rejected_2007_to_2018Q4.csv.gz\n",
            "drwxr-xr-x 1 root root       4096 Jun  1 21:50 sample_data\n",
            "drwxr-xr-x 3 root root       4096 Jun 12 18:00 sample_rejected_2007_to_2018Q4\n"
          ]
        }
      ],
      "source": [
        "!ls -al ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "puFFp3TqWNTA",
        "outputId": "acbeb014-86e2-468e-fd06-8b8003878132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: delta-spark in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from delta-spark) (4.11.4)\n",
            "Collecting pyspark<3.3.0,>=3.2.0\n",
            "  Using cached pyspark-3.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0.0->delta-spark) (3.7.4.3)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark<3.3.0,>=3.2.0->delta-spark) (0.10.9.3)\n",
            "Installing collected packages: pyspark\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 3.0.3\n",
            "    Uninstalling pyspark-3.0.3:\n",
            "      Successfully uninstalled pyspark-3.0.3\n",
            "Successfully installed pyspark-3.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install delta-spark\n",
        "from delta.tables import *\n",
        "from delta import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "BZx-1wZKXgVc"
      },
      "outputs": [],
      "source": [
        "deltaTable = DeltaTable.forPath(spark, \"output_rejected_2007_to_2018Q4\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6PqJN0vYF19",
        "outputId": "22e14d67-1f62-4dac-fa52-69b0867dcbe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- amount_requested: string (nullable = true)\n",
            " |-- application_date: string (nullable = true)\n",
            " |-- loan_title: string (nullable = true)\n",
            " |-- risk_score: string (nullable = true)\n",
            " |-- debt_to_income_ratio: string (nullable = true)\n",
            " |-- zip_code: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- employment_length: string (nullable = true)\n",
            " |-- policy_code: string (nullable = true)\n",
            " |-- user_read_time: timestamp (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# library.registerTempTable(\"library\")\n",
        "# new_info = spark.sql(\"SELECT *,CAST(rand(10)*id as bigint) count  from library\")\n",
        "\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "mutYdrFgYJgR"
      },
      "outputs": [],
      "source": [
        "df.registerTempTable(\"output_rejected_2007_to_2018Q4\")\n",
        "\n",
        "\n",
        "#just use moving avg based on year with rows \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "uNwroZS3ZgU8"
      },
      "outputs": [],
      "source": [
        "   kafka_df_2007_sql=\"\"\"SELECT \n",
        "        amount_requested ,\n",
        "        application_date ,\n",
        "        loan_title ,\n",
        "        risk_score ,   \n",
        "        debt_to_income_ratio ,\n",
        "        zip_code ,\n",
        "        state ,\n",
        "        employment_length ,            \n",
        "        policy_code ,\n",
        "        user_Read_time,\n",
        "        avg(risk_score) OVER( PARTITION by To_Date( application_date,'yyyy-MM-dd') ORDER BY user_Read_time ROWS BETWEEN 50 PRECEDING AND CURRENT ROW ) as RiskScoreMA50\n",
        "        FROM output_rejected_2007_to_2018Q4 where application_date between '2007-01-01' AND '2007-12-31'\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "mfNbOBZQZAP_"
      },
      "outputs": [],
      "source": [
        "new_info = spark.sql(kafka_df_2007_sql)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9N9YlDQZHE-",
        "outputId": "372b6f6a-a405-4704-fc62-e5133806241c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-----------------+\n",
            "|amount_requested|application_date|          loan_title|risk_score|debt_to_income_ratio|zip_code|state|employment_length|policy_code|      user_Read_time|    RiskScoreMA50|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-----------------+\n",
            "|          5000.0|      2007-11-15|               mm5yn|     676.0|              13.12%|   302xx|   GA|         < 1 year|        0.0|2022-06-12 14:01:...|            676.0|\n",
            "|         10000.0|      2007-11-15|           MONEYMAID|     465.0|              12.84%|   302xx|   GA|         < 1 year|        0.0|2022-06-12 14:01:...|            570.5|\n",
            "|          3000.0|      2007-11-15|         OPFLEETSIDE|     481.0|              21.92%|   302xx|   GA|          5 years|        0.0|2022-06-12 14:01:...|540.6666666666666|\n",
            "|          5000.0|      2007-11-15|              DR 124|     479.0|              51.85%|   302xx|   GA|        10+ years|        0.0|2022-06-12 14:01:...|           525.25|\n",
            "|          1500.0|      2007-11-15|     Cheryl B Dugars|     535.0|             123.33%|   302xx|   GA|         < 1 year|        0.0|2022-06-12 14:01:...|            527.2|\n",
            "|         15000.0|      2007-11-15|           walt12865|     615.0|              30.45%|   128xx|   NY|          4 years|        0.0|2022-06-12 14:01:...|541.8333333333334|\n",
            "|         25000.0|      2007-11-15|            dougwood|     690.0|              39.46%|   883xx|   NM|          2 years|        0.0|2022-06-12 14:01:...|            563.0|\n",
            "|          2000.0|      2007-11-15|            jrod7299|     602.0|               3.24%|   657xx|   MO|          3 years|        0.0|2022-06-12 14:01:...|          567.875|\n",
            "|          5000.0|      2007-11-15|              KIttie|     508.0|                  0%|   750xx|   TX|         < 1 year|        0.0|2022-06-12 14:01:...|561.2222222222222|\n",
            "|          7500.0|      2007-11-15|             NITA927|     593.0|              24.95%|   641xx|   MO|          4 years|        0.0|2022-06-12 14:01:...|            564.4|\n",
            "|          3000.0|      2007-11-15|             dsantos|     551.0|              17.94%|   110xx|   NY|          8 years|        0.0|2022-06-12 14:01:...|563.1818181818181|\n",
            "|          5000.0|      2007-11-15|              amylou|     404.0|               0.87%|   598xx|   MT|          5 years|        0.0|2022-06-12 14:01:...|549.9166666666666|\n",
            "|         10000.0|      2007-11-15|              Family|     685.0|                  0%|   463xx|   IN|          4 years|        0.0|2022-06-12 14:01:...|560.3076923076923|\n",
            "|         20000.0|      2007-11-15|              hYDSYS|     672.0|              14.46%|   871xx|   NM|        10+ years|        0.0|2022-06-12 14:01:...|568.2857142857143|\n",
            "|          2200.0|      2007-11-15|      WaywardJeepGuy|     624.0|              10.03%|   460xx|   IN|           1 year|        0.0|2022-06-12 14:01:...|            572.0|\n",
            "|          5000.0|      2007-11-15|U Can Lift My Bur...|     613.0|              15.85%|   968xx|   HI|          3 years|        0.0|2022-06-12 14:01:...|         574.5625|\n",
            "|         10000.0|      2007-11-15|           ndrizzo22|     630.0|               6.73%|   070xx|   NJ|        10+ years|        0.0|2022-06-12 14:01:...|577.8235294117648|\n",
            "|          2500.0|      2007-11-15|                KiKi|     624.0|              58.73%|   336xx|   FL|          5 years|        0.0|2022-06-12 14:01:...|580.3888888888889|\n",
            "|          1800.0|      2007-11-15|       colorckymntns|       0.0|                  0%|   800xx|   CO|         < 1 year|        0.0|2022-06-12 14:01:...|549.8421052631579|\n",
            "|         10000.0|      2007-11-15|             oms1969|     671.0|              35.31%|   301xx|   GA|           1 year|        0.0|2022-06-12 14:01:...|            555.9|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_info.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "ndEoYx4TZeML"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4a.keep consistency with schema enforcement\n",
        "# reference ttps://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html\n",
        "\n",
        "# Goal : Keep consistency Schema enforcement, also known as schema validation, is a safeguard in Delta Lake that ensures data quality by rejecting writes to a table that do not match the table’s schema.\n",
        "\n",
        "# Business Problem Solve : ensure data schema is consistent even on objects contain on cloud storage\n",
        "\n",
        "# Rather than automatically adding the new columns, Delta Lake enforces the schema and stops the write from occurring. To help identify which column(s) caused the mismatch, Spark prints out both schemas in the stack trace for comparison.\n",
        "\n",
        "# The following types of schema changes are eligible for schema evolution during table appends or overwrites: Adding new columns (this is the most common scenario) Changing of data types from NullType -> any other type, or upcasts from ByteType -> ShortType -> IntegerType"
      ],
      "metadata": {
        "id": "K5jCbtmWNlcm"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_info.write.format(\"delta\") \\\n",
        "           .mode(\"append\") \\\n",
        "           .save(\"output_rejected_2007_to_2018Q4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "RvuAWjNJNmfD",
        "outputId": "023c2411-3700-409a-d3c9-241fa26ea2ec"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-b8fa72dd0661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"delta\"\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"append\"\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_rejected_2007_to_2018Q4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mOther\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0mExtra\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mFor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mextra\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefer\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;31m# parse the return value to throw an exception if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mIt\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_return_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;31m# The original `get_return_value` is not patched, it's idempotent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mpatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_sql_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: A schema mismatch detected when writing to the Delta table (Table ID: e29ae659-447e-492f-8894-9d47b8ddd29e).\nTo enable schema migration using DataFrameWriter or DataStreamWriter, please set:\n'.option(\"mergeSchema\", \"true\")'.\nFor other operations, set the session configuration\nspark.databricks.delta.schema.autoMerge.enabled to \"true\". See the documentation\nspecific to the operation for details.\n\nTable schema:\nroot\n-- amount_requested: string (nullable = true)\n-- application_date: string (nullable = true)\n-- loan_title: string (nullable = true)\n-- risk_score: string (nullable = true)\n-- debt_to_income_ratio: string (nullable = true)\n-- zip_code: string (nullable = true)\n-- state: string (nullable = true)\n-- employment_length: string (nullable = true)\n-- policy_code: string (nullable = true)\n-- user_read_time: timestamp (nullable = true)\n\n\nData schema:\nroot\n-- amount_requested: string (nullable = true)\n-- application_date: string (nullable = true)\n-- loan_title: string (nullable = true)\n-- risk_score: string (nullable = true)\n-- debt_to_income_ratio: string (nullable = true)\n-- zip_code: string (nullable = true)\n-- state: string (nullable = true)\n-- employment_length: string (nullable = true)\n-- policy_code: string (nullable = true)\n-- user_Read_time: timestamp (nullable = true)\n-- RiskScoreMA50: double (nullable = true)\n\n         ;"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_info.write.format(\"delta\") \\\n",
        "          .option(\"mergeSchema\", \"true\")\\\n",
        "           .mode(\"append\") \\\n",
        "           .save(\"output_rejected_2007_to_2018Q4\")"
      ],
      "metadata": {
        "id": "D__KQqEFNzk_"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.format(\"delta\").load(\"output_rejected_2007_to_2018Q4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvHVfnIIOVH-",
        "outputId": "2f6793a8-62a5-4801-ca1d-fbd849151847"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[amount_requested: string, application_date: string, loan_title: string, risk_score: string, debt_to_income_ratio: string, zip_code: string, state: string, employment_length: string, policy_code: string, user_read_time: timestamp, RiskScoreMA50: double]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pShpgCGrOkIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data management with Delta Log\n",
        "keep Versioning\n",
        "https://databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html\n",
        "\n",
        "retrieve information on the operations, user, timestamp, and so on for each write to a Delta table by running the history command. The operations are returned in reverse chronological order. By default table history is retained for 30 days.# New Section"
      ],
      "metadata": {
        "id": "PBu5TPdFOrt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "spark.read.text(\"/content/drive/MyDrive/spark_download/output_rejected_2007_to_2018Q4/_delta_log\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "SWYGHxy_OshS",
        "outputId": "b0492fd6-f5cb-4a0f-b3a7-17e54a7eac62"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-b486704db5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/spark_download/output_rejected_2007_to_2018Q4/_delta_log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self, paths, wholetext, lineSep, pathGlobFilter, recursiveFileLookup)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_c0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'_c1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python/test_support/sql/ages.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_c0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'_c1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;31m# parse the return value to throw an exception if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mIt\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_return_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;31m# The original `get_return_value` is not patched, it's idempotent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mpatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture_sql_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/content/drive/MyDrive/spark_download/output_rejected_2007_to_2018Q4/_delta_log;"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onmzCoEmOuji",
        "outputId": "dc19908f-ea05-4973-d445-f2df0fa9d660"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2043728\n",
            "-rw-r--r-- 1 root root  392582231 Dec 17  2019  accepted_2007_to_2018Q4.csv.gz\n",
            "-rw-r--r-- 1 root root  255470782 Dec 17  2019  rejected_2007_to_2018Q4.csv.gz\n",
            "drwxr-xr-x 8 root root       4096 Jan 12 17:07  kafka_2.13-3.1.0\n",
            "drwxr-xr-x 1 root root       4096 Jun  1 21:50  sample_data\n",
            "-rw-r--r-- 1 root root         67 Jun 12 16:25  kaggle.json\n",
            "-rw-r--r-- 1 root root 1356507910 Jun 12 16:26  lending-club.zip\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 16:26  accepted_2007_to_2018q4.csv\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 16:26  rejected_2007_to_2018q4.csv\n",
            "drwxr-xr-x 2 root root       4096 Jun 12 18:41  spark-warehouse\n",
            "-rw-r--r-- 1 root root         67 Jun 12 19:45 'kaggle (1).json'\n",
            "-rw-r--r-- 1 root root   88130011 Jun 12 20:47  kafka_2.13-3.1.0.tgz\n",
            "drwxr-xr-x 3 root root      36864 Jun 12 22:03  output_rejected_2007_to_2018Q4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd output_rejected_2007_to_2018Q4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i2fSMUiO8bO",
        "outputId": "7a4e03b5-15b4-4356-8088-8b023acd9b50"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/output_rejected_2007_to_2018Q4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz2r4SEXO-Et",
        "outputId": "5fdfbfce-d174-4353-9068-0eb156c792f5"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 188448\n",
            "-rw-r--r-- 1 root root 14394942 Jun 12 21:01 part-00001-0b8a430d-504e-4ed6-9d85-a296749e4262-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 19463024 Jun 12 21:01 part-00000-52af9203-a751-4ab1-a2bb-3b85d9ce5d07-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 13321720 Jun 12 21:02 part-00002-626ee7b6-4822-4ccf-ba21-488d04d436c1-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 15206689 Jun 12 21:02 part-00003-449b428f-7996-44c9-94d4-df1a1d03fb0e-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 14641948 Jun 12 21:02 part-00004-311eca70-db0f-488e-9537-5396b8c2b30d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 13654079 Jun 12 21:02 part-00005-7aab53b3-93ca-41c3-a235-4a9989a07f8e-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 14515096 Jun 12 21:03 part-00006-88740ce5-53fa-4483-89bb-8075940a4112-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 13157527 Jun 12 21:03 part-00007-f4f110d3-a055-4db5-ae0f-7a794619d204-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 12797555 Jun 12 21:03 part-00008-f0343b03-168e-4a45-989c-b45db81d7aad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 13769605 Jun 12 21:03 part-00009-c3a90638-2a0e-4fff-b2dc-2a11b3ddc2f4-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 14421372 Jun 12 21:04 part-00010-91cdca3e-e11c-464b-b522-3e4b649e06f0-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 14092950 Jun 12 21:04 part-00011-0bfb4e28-f003-49b5-813d-8948041bb764-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root  4065563 Jun 12 21:04 part-00013-9f43a646-3477-4a87-9e2e-574e03172bf1-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root 14587448 Jun 12 21:04 part-00012-783a1d87-078e-4f0d-aa14-c5f895d20e80-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5967 Jun 12 22:03 part-00002-bc5820a1-15aa-46d4-a2d7-2ee7c7e97e1b-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7064 Jun 12 22:03 part-00000-0db23080-7387-4f6d-a1b7-167757a7445f-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4882 Jun 12 22:03 part-00004-fa72438e-4c9b-462a-83fc-f0c2f53410ea-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3655 Jun 12 22:03 part-00007-4a61b952-66fe-416c-b597-0d92187d342a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3331 Jun 12 22:03 part-00010-02404334-a9d4-4c7c-a482-0fa715e2c389-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6232 Jun 12 22:03 part-00012-aa3a08b9-049e-43eb-8103-5e5e3a24ce95-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3443 Jun 12 22:03 part-00013-68478939-644e-4691-924d-4ae07cb47bdd-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4910 Jun 12 22:03 part-00014-f10389bb-eb38-4111-9b4a-edaa1d0555d9-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7984 Jun 12 22:03 part-00015-cdad43da-bc4c-46eb-b843-af4e4adb80a4-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6169 Jun 12 22:03 part-00017-699013d7-ebec-4075-a3bd-79399b565385-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4585 Jun 12 22:03 part-00019-9d0f719f-394e-4d8b-a7b6-bc57446328ec-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3246 Jun 12 22:03 part-00020-698740d7-263d-404c-bca8-c2f3d6ddd63a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5391 Jun 12 22:03 part-00021-e72447ba-1445-4d2e-9d7e-1df2740adce3-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3219 Jun 12 22:03 part-00025-8a143f40-b77d-4000-b707-328df1bbe5c2-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3603 Jun 12 22:03 part-00024-a57833e7-c31f-4f4d-ac46-eecbecb0734d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4082 Jun 12 22:03 part-00026-0e12cd91-0c82-40ac-bbef-b5c8e382afff-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3439 Jun 12 22:03 part-00031-17b5341c-d648-4acd-a379-c8ff182a9b31-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3399 Jun 12 22:03 part-00032-ada0d76c-54e7-4a0c-b54a-8cfb59852e7d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3405 Jun 12 22:03 part-00034-753b35a4-3be8-423c-9bd2-6d2c43f76f9c-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4419 Jun 12 22:03 part-00035-2afa7973-7295-426d-9231-fc1045b56e2a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3747 Jun 12 22:03 part-00036-f70ca3d2-703a-444a-b93b-9b78e07e421f-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4299 Jun 12 22:03 part-00037-cad6307d-1b83-4803-8c0d-b2662efc66ce-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7197 Jun 12 22:03 part-00038-fe0f3764-cae9-42a0-bb6c-4141355d8c60-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3544 Jun 12 22:03 part-00039-72bab8f2-db6f-4d68-a927-7ed25e58993a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4861 Jun 12 22:03 part-00040-860e0bb4-9152-47d6-b53c-0eb75202507e-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4141 Jun 12 22:03 part-00041-d6a794cb-81d8-4866-b91f-8e2bde07880c-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4751 Jun 12 22:03 part-00042-efb718b0-f10d-4ce1-9bcd-02f0c6c62c75-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3229 Jun 12 22:03 part-00043-a9222bc2-ee99-4570-bc6e-a9793742b891-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5591 Jun 12 22:03 part-00044-f63a9436-a430-43a5-86de-d7e83fd7776a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5150 Jun 12 22:03 part-00047-1ce570dd-9c21-456b-bf03-6692cb62e7d6-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5361 Jun 12 22:03 part-00048-f094ccf7-24b9-4454-931b-c28b4228b5ef-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5151 Jun 12 22:03 part-00049-6f653f9d-5af8-41bc-9307-63961031baec-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5564 Jun 12 22:03 part-00050-d0efdf80-3359-4fe2-a66d-48ff29f3b99b-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3778 Jun 12 22:03 part-00051-9f73d2f6-46c1-4264-b551-90a62c63b721-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4843 Jun 12 22:03 part-00053-8f0d63a0-eabb-4239-9e61-f1067b7316d4-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3517 Jun 12 22:03 part-00054-d512015d-d3aa-4d82-a90b-9eeb66e45a7a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4906 Jun 12 22:03 part-00055-1111b4ff-e913-4712-ad16-eb94fba85c7f-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7307 Jun 12 22:03 part-00056-08536730-60d7-4303-bb53-c6484a84601e-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     8226 Jun 12 22:03 part-00058-98d87321-2a45-469f-81cf-b3ab6ddba1b6-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5800 Jun 12 22:03 part-00060-b484415b-b486-4acf-9d54-a94cffbe4faf-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7414 Jun 12 22:03 part-00066-67f029e8-1495-4e9e-b5d9-e2b896771f14-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5095 Jun 12 22:03 part-00065-b46789d1-c770-4810-8031-ea41632e5fc3-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3602 Jun 12 22:03 part-00070-d5638d1b-c02e-4f2e-8d6c-2b512f86dc2c-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7879 Jun 12 22:03 part-00071-b6652d60-6c05-4998-9b7c-5b5a655cdb6c-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3344 Jun 12 22:03 part-00072-c5038969-a5c6-466c-87f5-25f4619ee127-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3343 Jun 12 22:03 part-00073-4a259b25-c57a-4135-9f3d-b31c49bb78d4-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4312 Jun 12 22:03 part-00074-52ccaa48-8eb6-4679-9541-3123cc6bb8f4-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4952 Jun 12 22:03 part-00075-e4be45b1-0c46-47e8-af41-72286931becc-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3818 Jun 12 22:03 part-00078-4778dd19-ede4-4d0d-ac01-f447c6e8c6a7-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4098 Jun 12 22:03 part-00080-3f39f8b2-4a09-404b-b698-b7b05da0beb9-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3555 Jun 12 22:03 part-00082-9578d82e-1342-420b-b37b-e0e32a198cf3-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7546 Jun 12 22:03 part-00083-bf42f40c-9bf6-4d9c-87bb-e820ce51191d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3410 Jun 12 22:03 part-00085-16d9c2c7-e82f-424e-953c-1dbbcfb249aa-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3625 Jun 12 22:03 part-00086-2c9858fb-c885-4e87-9a53-7d7f885a19ad-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6548 Jun 12 22:03 part-00087-41c3f3de-3625-40df-8256-8ce91f79da02-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4588 Jun 12 22:03 part-00088-a6c1b05f-ec40-471f-bb30-2d1cd9dfa9e0-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7570 Jun 12 22:03 part-00089-48e18a32-611b-4f2a-af8a-41a29fa85a79-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7875 Jun 12 22:03 part-00091-a29bb766-3053-4670-a478-ec99ae64ce51-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4094 Jun 12 22:03 part-00095-765960c7-9144-490b-b944-a4341a873472-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4050 Jun 12 22:03 part-00092-cc53fa15-f76b-4078-b01c-ac1851efa02c-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3988 Jun 12 22:03 part-00096-6ba0d85e-1cbb-47f3-b6ac-c5ab123b8293-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4664 Jun 12 22:03 part-00097-7a01e79b-b654-41bf-8b75-6223b7a7d40d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3453 Jun 12 22:03 part-00098-dc450f2b-4125-4384-b1e1-44b7334b2d84-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3720 Jun 12 22:03 part-00099-cc99adbc-4785-4f39-bc97-8b5c525bf29e-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3742 Jun 12 22:03 part-00100-17e9a87a-2e3c-4a07-9527-05f83ec2bca8-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4021 Jun 12 22:03 part-00101-644b32ff-8225-4db5-a156-4726553cb8a5-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4517 Jun 12 22:03 part-00103-94e987cd-c572-4a97-b366-e228d39dbc3f-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6897 Jun 12 22:03 part-00104-01c2d8f1-255d-49cd-97bd-29c477fbb4a6-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3860 Jun 12 22:03 part-00105-cf0a0d55-6fbf-43b7-8a93-186900959db2-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4208 Jun 12 22:03 part-00106-cbe4763e-c461-4137-a3f8-25634566b995-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4110 Jun 12 22:03 part-00108-f608c826-65ef-4abc-ad77-1eaa18b8c347-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5032 Jun 12 22:03 part-00107-a479998f-41ed-4aba-9bc2-76ad72136ee3-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5050 Jun 12 22:03 part-00111-2aa7a94b-fcaa-4b3a-8227-0f994409af66-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3363 Jun 12 22:03 part-00113-cff93827-2f82-4a18-a2bc-b7f4b964e712-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3572 Jun 12 22:03 part-00114-42bd9e0e-e850-4393-a675-cea4005bd549-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5596 Jun 12 22:03 part-00115-23157355-79e8-4125-b8fc-0216013e522a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3916 Jun 12 22:03 part-00117-657fe2cd-88a8-45d8-ac40-380bb98a4286-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4038 Jun 12 22:03 part-00116-53f9a360-0a0f-45fe-b171-9370a7a0711b-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3279 Jun 12 22:03 part-00118-0fd0cbb6-b46a-4255-b3a9-c6852421a7ef-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3725 Jun 12 22:03 part-00119-f2c56cd1-208f-4e51-8e2c-3fb7e18df7a2-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3375 Jun 12 22:03 part-00120-a79cba15-1f5e-45bf-8fcf-047af934accd-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3214 Jun 12 22:03 part-00121-1d9e8ec8-13bf-48c2-9d72-43b8d0e2fda8-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3361 Jun 12 22:03 part-00125-14c91405-7194-41d7-b082-f22c9c79cb4a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6369 Jun 12 22:03 part-00124-117cb8f5-1599-40cf-94c7-846947dbc6cc-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3183 Jun 12 22:03 part-00126-877e5214-cb14-41bf-9d2c-6539be04f1c8-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6105 Jun 12 22:03 part-00127-5c857980-8a21-4ff1-bdc6-df9ccbfd41ce-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7026 Jun 12 22:03 part-00128-44459b32-f79d-4337-a489-7d456b8ef863-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4380 Jun 12 22:03 part-00129-99698f83-eb08-4970-9c0d-22216b545523-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4706 Jun 12 22:03 part-00130-0bd30bcb-4baf-40b1-ad55-b87f00e4a85a-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6037 Jun 12 22:03 part-00131-b6aa3f40-f29b-4187-aa28-6bda6bc110a0-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3925 Jun 12 22:03 part-00134-b14eeb79-7e0b-4900-8c78-7a7c522f054f-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3550 Jun 12 22:03 part-00136-d8f1a23e-455a-4a52-92f6-b7b7b1dd0eec-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3466 Jun 12 22:03 part-00140-6d7f745d-6e0c-47d8-a269-7d5f5b3452e6-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4564 Jun 12 22:03 part-00142-ddbd92f8-2aef-4008-9496-123208e57d95-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root    12658 Jun 12 22:03 part-00143-40a033f4-ffd1-4f81-a5d5-db5e34788131-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5112 Jun 12 22:03 part-00144-edf146cd-1086-4f4a-8afb-e6430879e92d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5559 Jun 12 22:03 part-00145-fbd37fac-709c-420e-a9a0-c1f2cd108c46-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5000 Jun 12 22:03 part-00146-dc23a857-901b-4352-ad88-090f4c5034cb-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5261 Jun 12 22:03 part-00148-df8b3ebb-5253-4a1c-9156-1c7ec3dd91e0-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5475 Jun 12 22:03 part-00149-0be2eb24-9b0a-4634-b50f-1328f02fdd64-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4626 Jun 12 22:03 part-00153-bdb1e6b6-d4ec-4aea-9185-cdac9687353e-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3415 Jun 12 22:03 part-00154-043ff918-84a3-408b-a77b-43dbabba3b93-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5101 Jun 12 22:03 part-00155-4b472a4f-1b33-49df-b0f9-b3bc44de2e90-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3101 Jun 12 22:03 part-00156-4aee2b70-42ec-46d6-8800-df50501c75df-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7255 Jun 12 22:03 part-00160-483db5b4-5b5d-42a8-814f-e42a10592077-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6302 Jun 12 22:03 part-00157-f73cc6a8-2148-4692-8372-9273dab53b5d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3083 Jun 12 22:03 part-00161-fd4f603c-897c-47c9-9968-56aeae43021e-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3722 Jun 12 22:03 part-00163-8daea803-1b38-415b-bfad-caa9a709d222-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6240 Jun 12 22:03 part-00164-e13f19dd-8f74-4094-af4a-f56035ae8536-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4981 Jun 12 22:03 part-00166-fd7cd551-f837-4b3e-90ff-420dc13565e7-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3379 Jun 12 22:03 part-00170-bcb5db83-0b54-4d38-8b81-95cb66aa0375-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7943 Jun 12 22:03 part-00168-ad43f2ad-5825-451b-ae1c-f9f805071ad0-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7159 Jun 12 22:03 part-00171-b8456549-5782-49d8-92f0-c7b5ebc8dd0d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3347 Jun 12 22:03 part-00174-4c394df5-fbff-4909-85f5-426c7aacbb85-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3628 Jun 12 22:03 part-00172-82760d99-4eaf-40ae-aac1-a71d0ed4567d-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3583 Jun 12 22:03 part-00175-9abe070a-f1c2-4db6-b86d-40bae5e3e173-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4925 Jun 12 22:03 part-00178-30582ccd-5a35-499e-9cb8-3d2d69ac4ee0-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     5432 Jun 12 22:03 part-00180-8d1f6eb5-ba5c-4468-9ba7-e8b12672a2a2-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     8239 Jun 12 22:03 part-00182-7dc255c8-cf7f-4694-8f8a-78b06f2749fd-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     7134 Jun 12 22:03 part-00187-c9f8c703-cf61-4978-8d4b-76c579e02a4c-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4597 Jun 12 22:03 part-00188-d36035fd-60b9-47fa-8f54-154391dbd045-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4389 Jun 12 22:03 part-00190-3276f3e6-1e96-4c97-8698-1107595c5ef9-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4124 Jun 12 22:03 part-00191-49cab9e5-7c4e-4d0b-8bd2-821df7f90329-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     6872 Jun 12 22:03 part-00194-b3bcaa3f-d762-4bd6-9a76-b052d87fb8d1-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     8158 Jun 12 22:03 part-00195-a83a3158-e819-41ab-8171-e627a90049cb-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     3600 Jun 12 22:03 part-00196-cee0df87-1567-490a-84cc-43f03cec7c47-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4389 Jun 12 22:03 part-00197-cec20cc7-fc3f-4676-8e60-235302f1b8d7-c000.snappy.parquet\n",
            "-rw-r--r-- 1 root root     4978 Jun 12 22:03 part-00198-c19db47b-f198-47ed-855c-77e39248059c-c000.snappy.parquet\n",
            "drwxr-xr-x 2 root root     4096 Jun 12 22:03 \u001b[0m\u001b[01;34m_delta_log\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.text(\"output_rejected_2007_to_2018Q4/_delta_log\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Rs7_CEO-4u",
        "outputId": "3f9c5c5b-60e2-4b03-c3db-c9145218fe61"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|{\"commitInfo\":{\"t...|\n",
            "|{\"metaData\":{\"id\"...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "|{\"add\":{\"path\":\"p...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fullHistoryDF = deltaTable.history().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIMHyH62PI05",
        "outputId": "119682b6-dd91-4034-d1b1-cc39d23c75fa"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
            "|version|           timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|\n",
            "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
            "|      1|2022-06-12 14:03:...|  null|    null|    WRITE|[mode -> Append, ...|null|    null|     null|          0|          null|         true|[numFiles -> 128,...|        null|\n",
            "|      0|2022-06-12 13:04:...|  null|    null|    WRITE|[mode -> Overwrit...|null|    null|     null|       null|          null|        false|[numFiles -> 14, ...|        null|\n",
            "+-------+--------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deltaTable.history().select(\"version\",\"operation\",\"timestamp\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlkWku5qPah-",
        "outputId": "a14abf67-6f21-4f35-fdb5-ee635ac20b3e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+--------------------+\n",
            "|version|operation|           timestamp|\n",
            "+-------+---------+--------------------+\n",
            "|      1|    WRITE|2022-06-12 14:03:...|\n",
            "|      0|    WRITE|2022-06-12 13:04:...|\n",
            "+-------+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deltaTable.history().select(\"version\",\"operation\",\"timestamp\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOa97l8qPfFn",
        "outputId": "1826014f-2e68-43d4-a3c6-93899ce14dcb"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+--------------------+\n",
            "|version|operation|           timestamp|\n",
            "+-------+---------+--------------------+\n",
            "|      1|    WRITE|2022-06-12 14:03:...|\n",
            "|      0|    WRITE|2022-06-12 13:04:...|\n",
            "+-------+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ###Time travel to compare data change and rolling back to previous version\n"
      ],
      "metadata": {
        "id": "9v_KO6-9PjzQ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   kafka_df_2008_2009_sql=\"\"\"SELECT \n",
        "        amount_requested ,\n",
        "        application_date ,\n",
        "        loan_title ,\n",
        "        risk_score ,   \n",
        "        debt_to_income_ratio ,\n",
        "        zip_code ,\n",
        "        state ,\n",
        "        employment_length ,            \n",
        "        policy_code ,\n",
        "        user_Read_time,\n",
        "        avg(risk_score) OVER( PARTITION by To_Date( application_date,'yyyy-MM-dd') ORDER BY user_Read_time ROWS BETWEEN 50 PRECEDING AND CURRENT ROW ) as RiskScoreMA50\n",
        "        FROM output_rejected_2007_to_2018Q4 where application_date between '2008-01-01' AND '2009-12-31'\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "Dyb8vsdmPtes"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_df_2008_2009 = spark.sql(kafka_df_2008_2009_sql)\n"
      ],
      "metadata": {
        "id": "4e6uxK9IPvsX"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_df_2008_2009.write.format(\"delta\") \\\n",
        "          .option(\"mergeSchema\", \"true\")\\\n",
        "           .mode(\"append\") \\\n",
        "           .save(\"output_rejected_2007_to_2018Q4\")"
      ],
      "metadata": {
        "id": "RvrA5FjBP5zn"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deltaTable.history().show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFBhorqrP_wt",
        "outputId": "b8b25709-e9b1-47f1-c293-adca54f12457"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------+------------+\n",
            "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                        |userMetadata|\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------+------------+\n",
            "|2      |2022-06-12 14:11:05.329|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |1          |null          |true         |[numFiles -> 197, numOutputBytes -> 3338769, numOutputRows -> 82587]    |null        |\n",
            "|1      |2022-06-12 14:03:46.478|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |0          |null          |true         |[numFiles -> 128, numOutputBytes -> 624885, numOutputRows -> 5274]      |null        |\n",
            "|0      |2022-06-12 13:04:51.479|null  |null    |WRITE    |[mode -> Overwrite, partitionBy -> []]|null|null    |null     |null       |null          |false        |[numFiles -> 14, numOutputBytes -> 192089518, numOutputRows -> 27648741]|null        |\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+------------------------------------------------------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.format(\"delta\").load(\"output_rejected_2007_to_2018Q4\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWoM3843QGzw",
        "outputId": "06d6237f-e4ce-4e61-c021-58068a5616a2"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-------------+\n",
            "|amount_requested|application_date|          loan_title|risk_score|debt_to_income_ratio|zip_code|state|employment_length|policy_code|      user_read_time|RiskScoreMA50|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-------------+\n",
            "|          1000.0|      2007-05-26|Wedding Covered b...|     693.0|                 10%|   481xx|   NM|          4 years|        0.0|2022-06-12 13:01:...|         null|\n",
            "|          1000.0|      2007-05-26|  Consolidating Debt|     703.0|                 10%|   010xx|   MA|         < 1 year|        0.0|2022-06-12 13:01:...|         null|\n",
            "|         11000.0|      2007-05-27|Want to consolida...|     715.0|                 10%|   212xx|   MD|           1 year|        0.0|2022-06-12 13:01:...|         null|\n",
            "|          6000.0|      2007-05-27|             waksman|     698.0|              38.64%|   017xx|   MA|         < 1 year|        0.0|2022-06-12 13:01:...|         null|\n",
            "|          1500.0|      2007-05-27|              mdrigo|     509.0|               9.43%|   209xx|   MD|         < 1 year|        0.0|2022-06-12 13:01:...|         null|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_df_2008_2009.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fi8qnYgQgTi",
        "outputId": "aa489993-950a-426e-ab21-eca077551266"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-----------------+\n",
            "|amount_requested|application_date|          loan_title|risk_score|debt_to_income_ratio|zip_code|state|employment_length|policy_code|      user_Read_time|    RiskScoreMA50|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-----------------+\n",
            "|         15000.0|      2009-07-25|         Consolidate|     602.0|               9.78%|   940xx|   CA|          6 years|        0.0|2022-06-12 14:12:...|            602.0|\n",
            "|         25000.0|      2009-07-25|         Consolidate|     747.0|              15.04%|   902xx|   CA|         < 1 year|        0.0|2022-06-12 14:12:...|            674.5|\n",
            "|          2000.0|      2009-07-25|         Debt Relief|     515.0|              16.83%|   481xx|   MI|         < 1 year|        0.0|2022-06-12 14:12:...|621.3333333333334|\n",
            "|         25000.0|      2009-07-25|    cephas tours,inc|     695.0|             106.25%|   712xx|   LA|          2 years|        0.0|2022-06-12 14:12:...|           639.75|\n",
            "|         20000.0|      2009-07-25|                    |     648.0|              40.47%|   705xx|   LA|          8 years|        0.0|2022-06-12 14:12:...|            641.4|\n",
            "|         20000.0|      2009-07-25|Request for Auto ...|     541.0|                  0%|   190xx|   PA|         < 1 year|        0.0|2022-06-12 14:12:...|624.6666666666666|\n",
            "|         18000.0|      2009-07-25|Securely Employed...|     620.0|              10.98%|   907xx|   CA|          5 years|        0.0|2022-06-12 14:12:...|            624.0|\n",
            "|         25000.0|      2009-07-25|         consolidate|      null|                 -1%|   182xx|   PA|        10+ years|        0.0|2022-06-12 14:12:...|            624.0|\n",
            "|          5000.0|      2009-07-25|    Help with school|     448.0|                260%|   239xx|   VA|          2 years|        0.0|2022-06-12 14:12:...|            602.0|\n",
            "|          1000.0|      2009-07-25|            pay rent|     479.0|                  0%|   752xx|   TX|         < 1 year|        0.0|2022-06-12 14:12:...|588.3333333333334|\n",
            "|         11000.0|      2009-07-25|New Roof For Dese...|       0.0|                  0%|   327xx|   FL|          2 years|        0.0|2022-06-12 14:12:...|            529.5|\n",
            "|         12000.0|      2009-07-25| THE LONGEST FUNERAL|     543.0|              16.46%|   481xx|   MI|        10+ years|        0.0|2022-06-12 14:12:...|530.7272727272727|\n",
            "|         10000.0|      2009-07-25|Looking to secure...|     491.0|              35.13%|   142xx|   NY|          7 years|        0.0|2022-06-12 14:12:...|527.4166666666666|\n",
            "|          1000.0|      2009-07-25|Help support the ...|     737.0|               9.47%|   787xx|   TX|        10+ years|        0.0|2022-06-12 14:12:...|543.5384615384615|\n",
            "|         12000.0|      2009-07-25|2003 Indian Roads...|     616.0|              17.34%|   280xx|   SC|         < 1 year|        0.0|2022-06-12 14:12:...|548.7142857142857|\n",
            "|          4500.0|      2009-07-25|                    |     659.0|               2.96%|   321xx|   FL|           1 year|        0.0|2022-06-12 14:12:...|556.0666666666667|\n",
            "|          3000.0|      2009-07-25|       Personal loan|     455.0|              19.96%|   604xx|   IL|          2 years|        0.0|2022-06-12 14:12:...|           549.75|\n",
            "|          2500.0|      2009-07-25|         save my son|     608.0|                1.2%|   612xx|   IL|         < 1 year|        0.0|2022-06-12 14:12:...|553.1764705882352|\n",
            "|         12000.0|      2009-07-25|           Personal |     571.0|                  3%|   100xx|   NY|          5 years|        0.0|2022-06-12 14:12:...|554.1666666666666|\n",
            "|          6000.0|      2009-07-25|                    |     618.0|              17.32%|   110xx|   NY|          2 years|        0.0|2022-06-12 14:12:...|557.5263157894736|\n",
            "+----------------+----------------+--------------------+----------+--------------------+--------+-----+-----------------+-----------+--------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deltaTable.history().show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shmjaYv_R8o6",
        "outputId": "c949f8d0-9eb2-42c1-96df-4e0b04e8229e"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-------------------------------------------------------------------------+------------+\n",
            "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                         |userMetadata|\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-------------------------------------------------------------------------+------------+\n",
            "|3      |2022-06-12 14:31:26.368|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |2          |null          |true         |[numFiles -> 200, numOutputBytes -> 274954297, numOutputRows -> 27617821]|null        |\n",
            "|2      |2022-06-12 14:11:05.329|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |1          |null          |true         |[numFiles -> 197, numOutputBytes -> 3338769, numOutputRows -> 82587]     |null        |\n",
            "|1      |2022-06-12 14:03:46.478|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |0          |null          |true         |[numFiles -> 128, numOutputBytes -> 624885, numOutputRows -> 5274]       |null        |\n",
            "|0      |2022-06-12 13:04:51.479|null  |null    |WRITE    |[mode -> Overwrite, partitionBy -> []]|null|null    |null     |null       |null          |false        |[numFiles -> 14, numOutputBytes -> 192089518, numOutputRows -> 27648741] |null        |\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-------------------------------------------------------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jl74QL71R-VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Starting year 2009 onwards, you get a new requirement to also calculate the MA100 of the Risk Score and store it, but the data schema must also to be trackable. Make a new column on the data store that has a new column called MA100, update the version of this data store, and do version controlling so that the original features can easily be accessed.\n"
      ],
      "metadata": {
        "id": "m_UiuRyoR-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   kafka_df_2009_sql=\"\"\"SELECT \n",
        "        amount_requested ,\n",
        "        application_date ,\n",
        "        loan_title ,\n",
        "        risk_score ,   \n",
        "        debt_to_income_ratio ,\n",
        "        zip_code ,\n",
        "        state ,\n",
        "        employment_length ,            \n",
        "        policy_code ,\n",
        "        user_Read_time,\n",
        "        avg(risk_score) OVER( PARTITION by To_Date( application_date,'yyyy-MM-dd') ORDER BY user_Read_time ROWS BETWEEN 100 PRECEDING AND CURRENT ROW ) as RiskScoreMA100\n",
        "        FROM output_rejected_2007_to_2018Q4 where application_date > '2009-01-01'\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "oRokLpuER8zT"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_df_2009 = spark.sql(kafka_df_2009_sql)\n"
      ],
      "metadata": {
        "id": "h5IRDn8rR82b"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_df_2009.write.format(\"delta\") \\\n",
        "          .option(\"mergeSchema\", \"true\")\\\n",
        "           .mode(\"append\") \\\n",
        "           .save(\"output_rejected_2007_to_2018Q4\")"
      ],
      "metadata": {
        "id": "fniFoUmvR853"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deltaTable.history().show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSYUxANXR88t",
        "outputId": "aa57ac37-8a55-4449-f55d-9968fd98271b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-------------------------------------------------------------------------+------------+\n",
            "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                         |userMetadata|\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-------------------------------------------------------------------------+------------+\n",
            "|3      |2022-06-12 14:31:26.368|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |2          |null          |true         |[numFiles -> 200, numOutputBytes -> 274954297, numOutputRows -> 27617821]|null        |\n",
            "|2      |2022-06-12 14:11:05.329|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |1          |null          |true         |[numFiles -> 197, numOutputBytes -> 3338769, numOutputRows -> 82587]     |null        |\n",
            "|1      |2022-06-12 14:03:46.478|null  |null    |WRITE    |[mode -> Append, partitionBy -> []]   |null|null    |null     |0          |null          |true         |[numFiles -> 128, numOutputBytes -> 624885, numOutputRows -> 5274]       |null        |\n",
            "|0      |2022-06-12 13:04:51.479|null  |null    |WRITE    |[mode -> Overwrite, partitionBy -> []]|null|null    |null     |null       |null          |false        |[numFiles -> 14, numOutputBytes -> 192089518, numOutputRows -> 27648741] |null        |\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-------------------------------------------------------------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PGwZziWSR8_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "42f3JAorR9CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yYbOASQ0R9FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DuRnlD8bR9IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R0qF1g0KR9LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. The team found out that they did not actually want the MA50, but the EMA50 for the purpose of this calculation (want to edit the feature without changing the name). In this case, they do not want a new column for the EMA50, but replace the existing MA50 with new logic. Edit the logic for the feature creation pipeline, and version control the new version of the feature store.\n"
      ],
      "metadata": {
        "id": "1cmlQkdGQmF6"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. The team found out that they did not actually want the MA50, but the EMA50 for the purpose of this calculation (want to edit the feature without changing the name). In this case, they do not want a new column for the EMA50, but replace the existing MA50 with new logic. Edit the logic for the feature creation pipeline, and version control the new version of the feature store.\n",
        "# New Section"
      ],
      "metadata": {
        "id": "3M_mSXs3Rxow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "7_wGMuyaQ2xA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "kafka-stream-data-lake.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVt/tiO8WdLshnUacaEIKZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}